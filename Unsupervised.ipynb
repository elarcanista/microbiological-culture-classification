{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Preliminars"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "from pandas import DataFrame\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from mpl_toolkits.mplot3d import Axes3D\r\n",
    "import numpy as np\r\n",
    "import random\r\n",
    "import colorsys\r\n",
    "from functools import partial\r\n",
    "import math"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_clusters(clusters, attributes):\r\n",
    "    fig, axs = plt.subplots(1, len(clusters)+1, subplot_kw=dict(projection='3d'))\r\n",
    "\r\n",
    "    colors = [colorsys.hsv_to_rgb(i/len(clusters), 1, 1) for i in range(len(clusters))]\r\n",
    "\r\n",
    "    for ax, (name, data), color in zip(axs, clusters.items(), colors):\r\n",
    "        ax.set_title(name)\r\n",
    "        ax.scatter(data.loc[:, attributes[0]],\r\n",
    "                data.loc[:, attributes[1]],\r\n",
    "                data.loc[:, attributes[2]], color=color)\r\n",
    "        ax.set_xlabel(attributes[0])\r\n",
    "        ax.set_ylabel(attributes[1])\r\n",
    "        ax.set_zlabel(attributes[2])\r\n",
    "        axs[-1].scatter(data.loc[:, attributes[0]],\r\n",
    "                data.loc[:, attributes[1]],\r\n",
    "                data.loc[:, attributes[2]], color=color)\r\n",
    "\r\n",
    "    axs[-1].set_title('Total')\r\n",
    "    axs[-1].set_xlabel(attributes[0])\r\n",
    "    axs[-1].set_ylabel(attributes[1])\r\n",
    "    axs[-1].set_zlabel(attributes[2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def sampling_uniform(data, sample_proportions):\r\n",
    "    assert sum(sample_proportions.values()) == 1, sum(sample_proportions.values())\r\n",
    "\r\n",
    "    shuffled_data = data.sample(frac=1)\r\n",
    "    slice_low = 0\r\n",
    "    samples = {}\r\n",
    "    for sample, proportion in sample_proportions.items():\r\n",
    "        slice_high = slice_low + proportion\r\n",
    "        samples[sample] = shuffled_data.iloc[int(len(shuffled_data) * slice_low) : int(len(shuffled_data) * slice_high), :]\r\n",
    "        slice_low = slice_high\r\n",
    "\r\n",
    "    return samples"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Distances"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def dist_euclidean2(p1, p2):\r\n",
    "    d = p1 - p2\r\n",
    "    return d.dot(d)\r\n",
    "\r\n",
    "def dist_manhattan(p1, p2):\r\n",
    "    return abs(p1 - p2).sum()\r\n",
    "\r\n",
    "# precision matrix is the inverse of the covariance matrix\r\n",
    "def dist_mahalanobis2(precision, p1, p2):\r\n",
    "    d = p1 - p2\r\n",
    "    return d.transpose().dot(precision).dot(d)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clustering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def centroids(points, k):\r\n",
    "    return [points[points['Cluster'] == cluster].mean() for cluster in range(k)]\r\n",
    "    \r\n",
    "def init_randompartition(points, k):\r\n",
    "    points['Cluster'] = [random.randrange(0, k) for i in range(points.shape[0])]\r\n",
    "    means = centroids(points, k)\r\n",
    "    return points, means\r\n",
    "\r\n",
    "def cluster_kmeans(points, dist, k):\r\n",
    "    points, means = init_randompartition(points, k)\r\n",
    "\r\n",
    "    while True:\r\n",
    "        for r in points.iterrows():\r\n",
    "            print(r)\r\n",
    "            print(list(map(partial(dist, points.iloc[1]), means)))\r\n",
    "        print(points.iloc[1], np.argmin(map(partial(dist, points.iloc[1]), means)))\r\n",
    "        clusters_new = [np.argmin(map(partial(dist, r), means)) for r in points.iterrows()]\r\n",
    "        points['Cluster'] = clusters_new\r\n",
    "        means_new = centroids(points, k)\r\n",
    "        delta = np.mean([dist(p1, p2) for p1, p2 in zip(means, means_new)])\r\n",
    "        assert not np.isnan(delta)\r\n",
    "        print(delta)\r\n",
    "        if(delta < 0.01):\r\n",
    "            return points, means_new\r\n",
    "        means = means_new"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,20)\r\n",
    "data = pd.read_csv('Iris.csv', index_col=0)\r\n",
    "sample = sampling_uniform(data.drop(['Species'], axis=1), {'Train': 0.6, 'Validation': 0.2, 'Test': 0.2})\r\n",
    "plot_clusters(sample, ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm'])\r\n",
    "cluster_kmeans(sample['Train'], dist_euclidean2, 3)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "1a74cfba15cb2a7e1711077e0bf40c4aa90b3e0e84105adac214ba76b6a8694a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}