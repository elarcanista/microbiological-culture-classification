{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Preliminars"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import random\n",
    "import colorsys\n",
    "from functools import partial\n",
    "from functools import reduce\n",
    "\n",
    "filename = 'Iris.csv'\n",
    "sample_proportions = {'Train': 0.6, 'Validation': 0.2, 'Test': 0.2}\n",
    "k = 3\n",
    "\n",
    "data = pd.read_csv(filename, index_col=0)\n",
    "name_to_index = {name: i for i, name in enumerate(data.iloc[:, -1].unique())}\n",
    "i_to_category = {i: name for name, i in name_to_index.items()}\n",
    "data.iloc[:, -1] = \\\n",
    "    data.iloc[:, -1].apply(lambda x: name_to_index[x])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_color(N, n):\n",
    "    return colorsys.hsv_to_rgb(n/N, 0.65, 1)\n",
    "\n",
    "\n",
    "def plot_clusters(data, i_to_name, centroids=pd.DataFrame(columns=data.columns)):\n",
    "    plt.rcParams[\"figure.figsize\"] = (8,8)\n",
    "    fig, axs = plt.subplots(data.shape[1]-1, data.shape[1]-1,\n",
    "        sharex='col', sharey='row', constrained_layout=True)\n",
    "\n",
    "    get_colorN = lambda x: get_color(len(i_to_name), x)\n",
    "    colors = data.iloc[:, -1].apply(get_colorN)\n",
    "    color_clusters = [get_colorN(i) for i in range(len(i_to_name))]\n",
    "    color_centroids = [get_colorN(i) for i in range(centroids.shape[0])]\n",
    "\n",
    "    for r, r_name in enumerate(data.columns[:-1]):\n",
    "        y_data = data.iloc[:, r]\n",
    "        for c, c_name in enumerate(data.columns[:-1]):\n",
    "            if r != c:\n",
    "                axs[r, c].scatter(data.iloc[:, c], y_data, c=colors)\n",
    "                axs[r, c].scatter(centroids.iloc[:, c], centroids.iloc[:, r], c=color_centroids,\n",
    "                                  marker=(5, 1), edgecolors='black', linewidths=1)\n",
    "            else:\n",
    "                axs[r, c].text(0.5, 0.5, r_name,\n",
    "                               fontweight='bold',\n",
    "                               horizontalalignment='center',\n",
    "                               verticalalignment='center',\n",
    "                               transform=axs[r, c].transAxes)\n",
    "\n",
    "    legend_elements = [Line2D([0], [0], label=i_to_name[i], markerfacecolor=c,\n",
    "                              color='w', marker='s', markersize=12)\n",
    "                       for i, c in enumerate(color_clusters)]\n",
    "    fig.legend(handles=legend_elements, loc='center')\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def sampling_uniform(data, sample_proportions):\n",
    "    assert sum(sample_proportions.values()) == 1, \\\n",
    "        sum(sample_proportions.values())\n",
    "\n",
    "    shuffled_data = data.sample(frac=1)\n",
    "    N = len(shuffled_data)\n",
    "    p_low = 0\n",
    "    index_to_name = {}\n",
    "    for i, (sample, proportion) in enumerate(sample_proportions.items()):\n",
    "        p_high = p_low + proportion\n",
    "        i_low, i_high = int(N * p_low), int(N * p_high)\n",
    "        shuffled_data.iloc[i_low: i_high, -1] = i\n",
    "        index_to_name[i] = sample\n",
    "        p_low = p_high\n",
    "\n",
    "    return shuffled_data, index_to_name\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Distances"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def dist_euclidean2(p1, p2):\n",
    "    d = p1.iloc[:-1] - p2.iloc[:-1]\n",
    "    return d.dot(d)\n",
    "\n",
    "def dist_manhattan(p1, p2):\n",
    "    return abs(p1.iloc[:-1] - p2.iloc[:-1]).sum()\n",
    "\n",
    "# precision matrix is the inverse of the covariance matrix\n",
    "def dist_mahalanobis2(precision, p1, p2):\n",
    "    d = p1.iloc[:-1] - p2.iloc[:-1]\n",
    "    return d.transpose().dot(precision).dot(d)\n",
    "\n",
    "def normalize(points):\n",
    "    min_elem = points.iloc[:,:-1].min()\n",
    "    scale = points.iloc[:,:-1].max() - min_elem\n",
    "    def f(x): return ((x.iloc[:-1]-min_elem)/scale).append(x[-1:])\n",
    "    def g(x): return (x.iloc[:-1]*scale + min_elem).append(x[-1:])\n",
    "    return points.apply(f, axis=1), lambda x: x.apply(g, axis=1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clustering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_centroids(points):\n",
    "    points = points.groupby(points.columns[-1]).mean().reset_index()\n",
    "    cols = points.columns.tolist()\n",
    "    return points[cols[1:] + cols[:1]]\n",
    "    \n",
    "def init_randompartition(points, k):\n",
    "    points.iloc[:,-1] = [random.randrange(0, k) for i in range(points.shape[0])]\n",
    "    means = get_centroids(points)\n",
    "    return points, means\n",
    "\n",
    "def cluster_kmeans(points, dist, k):\n",
    "    points, means = init_randompartition(points, k)\n",
    "    while True:\n",
    "        clusters_new = [means.apply(lambda m: dist(r, m), axis=1).argmin()\n",
    "                        for _, r in points.iterrows()]\n",
    "        points.iloc[:,-1] = clusters_new\n",
    "        means_new = get_centroids(points)\n",
    "        means_i, means_new_i = means.iterrows(), means_new.iterrows()\n",
    "        delta = np.sum([dist(u[1], v[1]) for u, v in zip(means_i, means_new_i)])\n",
    "        print(delta)\n",
    "        assert not np.isnan(delta)\n",
    "        if(delta/k < 0.001):\n",
    "            return points, {i:i for i in range(k)}, means\n",
    "        means = means_new\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data, revert_norm = normalize(data)\n",
    "plot_clusters(data, i_to_category)\n",
    "\n",
    "sample, i_to_partition = sampling_uniform(data, sample_proportions)\n",
    "#plot_clusters(sample, i_to_partition)\n",
    "\n",
    "trained, i_to_partition, centroids = \\\n",
    "    cluster_kmeans(sample.copy(), dist_euclidean2, k)\n",
    "plot_clusters(revert_norm(trained), i_to_partition, revert_norm(centroids))\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "1a74cfba15cb2a7e1711077e0bf40c4aa90b3e0e84105adac214ba76b6a8694a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}